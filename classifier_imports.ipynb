{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e90c3852-2cd5-462f-84e1-fab1bdc45a92",
   "metadata": {},
   "source": [
    "**Load audio file from database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cfa2f26-64bc-4d56-b06e-06ec9c76f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_music_file(file_path: str):\n",
    "    \"\"\"Loads a target music file path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        File path of song\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    recorded_audio: np.ndarray\n",
    "        Audio samples\n",
    "    \"\"\"\n",
    "\n",
    "    audio, samp_rate = librosa.load(file_path, sr=SAMPLING_RATE, mono=True)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7936d67c-a2ba-4c32-8602-b83f1acc2686",
   "metadata": {},
   "source": [
    "**Mic audio to integers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d69c9661-05f6-430a-abf5-6df3c7dcc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mic_frames_to_audio(frames: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Converts frames taken from microphone to 16-bit integers\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    frames : np.ndarray\n",
    "        List of bytes recorded from a microphone\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Bytes converted to 16-bit integers\n",
    "    \"\"\"\n",
    "\n",
    "    return np.hstack([np.frombuffer(i, np.int16) for i in frames])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f506cd-f774-47aa-a452-41d345fd8b61",
   "metadata": {},
   "source": [
    "**Clip Maker function to test classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e39042-e833-41c1-afba-b5c6956dded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_clips(samples: np.ndarray, *, desired_length: int, count: int):\n",
    "    \"\"\"Takes audio samples and cuts {count} number of {desired_length} clips.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples: np.ndarray\n",
    "        Array of audio samples\n",
    "\n",
    "    desired_length: int\n",
    "        Length of each clip in seconds\n",
    "\n",
    "    count: int\n",
    "        Total number of clips\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray, shape-(count,N)\n",
    "        2-D array with {count} number of clip samples\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    N = len(samples)\n",
    "    sampling_rate = SAMPLING_RATE\n",
    "    T = N / sampling_rate\n",
    "    assert desired_length < T, \"length of clip cannot be greater than song length\"\n",
    "    \n",
    "    percent_of_duration = desired_length / T\n",
    "    samples_per_clip = int(percent_of_duration * len(samples))\n",
    "    \n",
    "    clip_samples = []\n",
    "\n",
    "    for i in range(count):\n",
    "        random_sample_idx = random.randrange(0, N - samples_per_clip)\n",
    "        clip_sample = samples[random_sample_idx : random_sample_idx + samples_per_clip]\n",
    "        clip_samples.append(clip_sample)\n",
    "\n",
    "    return np.array(clip_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d8224b-5125-49dd-a3b7-793e57f6229c",
   "metadata": {},
   "source": [
    "**Plot and return figure and axes for Spectrogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd83e9e7-f796-4ae0-85d6-0d3c4ca9a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dig_samp_to_spec_plot (samples: np.ndarray):\n",
    "    # data = np.hstack([np.frombuffer(i, np.int16) for i in frames])\n",
    "\n",
    "    # using matplotlib's built-in spectrogram function\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    S, freqs, times, im = ax.specgram(\n",
    "        samples,\n",
    "        NFFT=4096,\n",
    "        Fs=SAMPLING_RATE,\n",
    "        window=mlab.window_hanning,\n",
    "        noverlap=4096 // 2,\n",
    "        mode='magnitude'\n",
    "    )\n",
    "    ax.set_ylim(0, 10000)\n",
    "    ax.set_xlabel(\"time (sec)\")\n",
    "    ax.set_ylabel(\"frequency (Hz)\")\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723cc77f-cbc3-4aa2-8dc2-9344da1ccf92",
   "metadata": {},
   "source": [
    "**Return Spectrogram 2-D Array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9b738d8-b534-4d4c-8738-994a78ac0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dig_samp_to_spec(samples: np.ndarray):\n",
    "    \"\"\"Takes a 1-D sampled audio array and returns a 2-D spectrogram.\"\"\"\n",
    "    \n",
    "    S, freqs, times = mlab.specgram(\n",
    "    samples,\n",
    "    NFFT=4096,\n",
    "    Fs=SAMPLING_RATE,\n",
    "    window=mlab.window_hanning,\n",
    "    noverlap=int(4096 / 2),\n",
    "    mode='magnitude'\n",
    "    )\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb13191-94bd-48c9-a33b-b162dc530b7d",
   "metadata": {},
   "source": [
    "**Return the peaks of a spectrogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c416378-8fcf-4496-829a-6553367297a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def _peaks(data_2d, rows, cols, amp_min):\n",
    "    \"\"\"\n",
    "    A Numba-optimized 2-D peak-finding algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray, shape-(H, W)\n",
    "        The 2D array of data in which local peaks will be detected.\n",
    "\n",
    "    rows : numpy.ndarray, shape-(N,)\n",
    "        The 0-centered row indices of the local neighborhood mask\n",
    "    \n",
    "    cols : numpy.ndarray, shape-(N,)\n",
    "        The 0-centered column indices of the local neighborhood mask\n",
    "        \n",
    "    amp_min : float\n",
    "        All amplitudes at and below this value are excluded from being local \n",
    "        peaks.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Tuple[int, int]]\n",
    "        (row, col) index pair for each local peak location. \n",
    "    \"\"\"\n",
    "    peaks = []\n",
    "    \n",
    "    # iterate over the 2-D data in col-major order\n",
    "    for c, r in np.ndindex(*data_2d.shape[::-1]):\n",
    "        if data_2d[r, c] <= amp_min:\n",
    "            continue\n",
    "\n",
    "        for dr, dc in zip(rows, cols):\n",
    "            if dr == 0 and dc == 0:\n",
    "                continue\n",
    "\n",
    "            if not (0 <= r + dr < data_2d.shape[0]):\n",
    "                dr *= -1\n",
    "\n",
    "            if not (0 <= c + dc < data_2d.shape[1]):\n",
    "                dc *= -1\n",
    "\n",
    "            if data_2d[r, c] < data_2d[r + dr, c + dc]:\n",
    "                break\n",
    "        else:\n",
    "            peaks.append((r, c))\n",
    "    return peaks\n",
    "\n",
    "def local_peak_locations(data_2d, neighborhood, amp_min):\n",
    "    \"\"\"\n",
    "    From \n",
    "    Defines a local neighborhood and finds the local peaks\n",
    "    in the spectrogram, which must be larger than the specified `amp_min`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray, shape-(H, W)\n",
    "        The 2D array of data in which local peaks will be detected\n",
    "    \n",
    "    neighborhood : numpy.ndarray, shape-(h, w)\n",
    "        A boolean mask indicating the \"neighborhood\" in which each\n",
    "        datum will be assessed to determine whether or not it is\n",
    "        a local peak. h and w must be odd-valued numbers\n",
    "        \n",
    "    amp_min : float\n",
    "        All amplitudes at and below this value are excluded from being local \n",
    "        peaks.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Tuple[int, int]]\n",
    "        (row, col) index pair for each local peak location.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The local peaks are returned in column-major order.\n",
    "    \"\"\"\n",
    "    rows, cols = np.where(neighborhood)\n",
    "    assert neighborhood.shape[0] % 2 == 1\n",
    "    assert neighborhood.shape[1] % 2 == 1\n",
    "\n",
    "    rows -= neighborhood.shape[0] // 2\n",
    "    cols -= neighborhood.shape[1] // 2\n",
    "    \n",
    "    return _peaks(data_2d, rows, cols, amp_min=amp_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a839dcb-70fb-4476-8a55-03eaf1e88f65",
   "metadata": {},
   "source": [
    "**Turn peaks to fingerprints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de06fa17-dbc5-4ffc-beb9-a76bece5c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_peaks_to_fingerprints(local_peaks: List[Tuple[int, int]], num_fanout: int):\n",
    "\n",
    "    result = [] #should be a list of lists\n",
    "\n",
    "    if num_fanout <= len(local_peaks):\n",
    "        for i in range(len(local_peaks) - num_fanout): # subtract because it had to be only peaks after, and dont want index out of bounds error\n",
    "            i_fingerprints = []\n",
    "            i_freq, i_time = local_peaks[i]\n",
    "            for j in range(1, num_fanout+1):\n",
    "                f_freq, f_time = local_peaks[i+j]\n",
    "                i_fingerprints += [(i_freq, f_freq, f_time - i_time)]\n",
    "            \n",
    "            result += i_fingerprints\n",
    "        \n",
    "        return result # should be a 2d list, that can then be zipped w the peaks if we need to know which peak its associated with\n",
    "    else:\n",
    "        return \"IndexError\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da26b067-e42e-4743-9cb4-353e67873107",
   "metadata": {},
   "source": [
    "**Set cutoff for amplitude to disregard background noise in real world samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6459a1f-ecc7-4c39-a8f5-e3cd9c138a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cutoff_amp(S: np.ndarray, percentile: float):\n",
    "    \"\"\"Returns the log_amplitude of a target spectrogram that will be the cutoff for background noise\n",
    "       in real world samples. Calculated using decimal part percentile.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    S : numpy.ndarray\n",
    "        The target spectrogram\n",
    "\n",
    "    percentile : float\n",
    "         A demical < 1.0 for which the cutoff is greater than or equal to the {percentile}\n",
    "         percentile of log_amplitudes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Cutoff amplitude\"\"\"\n",
    "\n",
    "    S = S.ravel()  # ravel flattens 2D spectrogram into a 1D array\n",
    "    ind = round(len(S) * percentile)  # find the index associated with the percentile amplitude\n",
    "    cutoff_amplitude = np.partition(S, ind)[ind]  # find the actual percentile amplitude\n",
    "    \n",
    "    return cutoff_amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef941656-5b1e-455e-830d-f313199b6902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
