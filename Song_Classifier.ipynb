{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5593b271-deea-40e6-80b4-ad0b99b2062e",
   "metadata": {},
   "source": [
    "### Song Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4849b4-a677-4605-adec-8ded5086f0fe",
   "metadata": {},
   "source": [
    "##### Date: 7/11/2024\n",
    "##### Authors: Edwardia Fosah, Ye Yint Hmine, Zoe Granadoz, Bryan Wang, Manya Tandon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f3577c-7934-46d5-b9ad-ab8556c87153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manya\\AppData\\Local\\Temp\\ipykernel_23004\\3056476876.py:10: DeprecationWarning: Please use `generate_binary_structure` from the `scipy.ndimage` namespace, the `scipy.ndimage.morphology` namespace is deprecated.\n",
      "  from scipy.ndimage.morphology import generate_binary_structure\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from microphone import record_audio\n",
    "from IPython.display import Audio\n",
    "from typing import Tuple\n",
    "import librosa\n",
    "\n",
    "from numba import njit\n",
    "from scipy.ndimage.morphology import generate_binary_structure\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c563a05a-b262-400f-bd09-1da7f33673b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE = 44100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed7e874-477d-4fca-8a98-2f97c1f2e95e",
   "metadata": {},
   "source": [
    "**Load audio file from database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d0a6899-1083-4c4f-95ef-8b34db989ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_music_file(file_path: str):\n",
    "    \"\"\"Loads a target music file path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        File path of song\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    recorded_audio: np.ndarray\n",
    "        Audio samples\n",
    "\n",
    "    sampling_rate: int\n",
    "    \"\"\"\n",
    "\n",
    "    audio, samp_rate = librosa.load(file_path, sr=SAMPLING_RATE, mono=True)\n",
    "    return audio, samp_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582a5b4b-8222-444f-90f5-e62dd044f8a4",
   "metadata": {},
   "source": [
    "**Audio to integers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82cc4c8f-c8c3-41aa-a4d6-1df6ea2614d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mic_frames_to_audio(frames: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Converts frames taken from microphone to 16-bit integers\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    frames : np.ndarray\n",
    "        List of bytes recorded from a microphone\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Bytes converted to 16-bit integers\n",
    "    \"\"\"\n",
    "\n",
    "    return np.hstack([np.frombuffer(i, np.int16) for i in frames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e33a66bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_from_mic(listen_time, path_name = \"\"): # just a wrapper/helper function for us to use when testing entire model w/laptops\n",
    "    \n",
    "    frames, sample_rate = record_audio(listen_time)\n",
    "    samples = convert_mic_frames_to_audio(frames)\n",
    "    \n",
    "    Audio(samples, rate = sample_rate)\n",
    "\n",
    "    if path_name != \"\": # can also use fun when making test audios, just so its faster\n",
    "        np.save(path_name, np.hstack((sample_rate, samples)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3963597-a0d7-4697-a3ec-17a551338317",
   "metadata": {},
   "source": [
    "*optional*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9206fdfc-ff11-483b-a7f1-7d235ca67be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_clips(samples: np.ndarray, *, desired_length: int, count: int):\n",
    "    \"\"\"Takes audio samples and cuts {count} number of {desired_length} clips.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples: np.ndarray\n",
    "        Array of audio samples\n",
    "\n",
    "    desired_length: int\n",
    "        Length of each clip in seconds\n",
    "\n",
    "    count: int\n",
    "        Total number of clips\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray, shape-(count,N)\n",
    "        2-D array with {count} number of clip samples\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    N = len(samples)\n",
    "    sampling_rate = SAMPLING_RATE\n",
    "    T = N / sampling_rate\n",
    "    percent_of_duration = desired_length / T\n",
    "    samples_per_clip = int(percent_of_duration * len(samples))\n",
    "    \n",
    "    clip_samples = []\n",
    "\n",
    "    for i in range(count):\n",
    "        random_sample_idx = random.randrange(0, N - samples_per_clip)\n",
    "        clip_sample = samples[random_sample_idx : random_sample_idx + samples_per_clip]\n",
    "        clip_samples.append(clip_sample)\n",
    "\n",
    "    return np.array(clip_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ba122-d810-4f0d-8118-9176695d3a83",
   "metadata": {},
   "source": [
    "**Plot Spectrogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cfd3b4-e0dc-425a-9ef3-a3cfbaaf5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dig_samp_to_spec (samples):\n",
    "    # data = np.hstack([np.frombuffer(i, np.int16) for i in frames])\n",
    "\n",
    "    # using matplotlib's built-in spectrogram function\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    S, freqs, times, im = ax.specgram(\n",
    "        data,\n",
    "        NFFT=4096,\n",
    "        Fs=SAMPLING_RATE,\n",
    "        window=mlab.window_hanning,\n",
    "        noverlap=4096 // 2,\n",
    "        mode='magnitude'\n",
    "    )\n",
    "    ax.set_ylim(0, 10000)\n",
    "    ax.set_xlabel(\"time (sec)\")\n",
    "    ax.set_ylabel(\"frequency (Hz)\")\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab7902-bfd4-4a5d-9f1d-3a793a35888d",
   "metadata": {},
   "source": [
    "**Find Peaks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5184b499-b9be-4f36-9b7f-c29d03d08e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def _peaks(data_2d, rows, cols, amp_min):\n",
    "    \"\"\"\n",
    "    A Numba-optimized 2-D peak-finding algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray, shape-(H, W)\n",
    "        The 2D array of data in which local peaks will be detected.\n",
    "\n",
    "    rows : numpy.ndarray, shape-(N,)\n",
    "        The 0-centered row indices of the local neighborhood mask\n",
    "    \n",
    "    cols : numpy.ndarray, shape-(N,)\n",
    "        The 0-centered column indices of the local neighborhood mask\n",
    "        \n",
    "    amp_min : float\n",
    "        All amplitudes at and below this value are excluded from being local \n",
    "        peaks.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Tuple[int, int]]\n",
    "        (row, col) index pair for each local peak location. \n",
    "    \"\"\"\n",
    "    peaks = []\n",
    "    \n",
    "    # iterate over the 2-D data in col-major order\n",
    "    for c, r in np.ndindex(*data_2d.shape[::-1]):\n",
    "        if data_2d[r, c] <= amp_min:\n",
    "            continue\n",
    "\n",
    "        for dr, dc in zip(rows, cols):\n",
    "            if dr == 0 and dc == 0:\n",
    "                continue\n",
    "\n",
    "            if not (0 <= r + dr < data_2d.shape[0]):\n",
    "                dr *= -1\n",
    "\n",
    "            if not (0 <= c + dc < data_2d.shape[1]):\n",
    "                dc *= -1\n",
    "\n",
    "            if data_2d[r, c] < data_2d[r + dr, c + dc]:\n",
    "                break\n",
    "        else:\n",
    "            peaks.append((r, c))\n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019be8a-3655-451a-95cc-ce10a1ca8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_peak_locations(data_2d, neighborhood, amp_min):\n",
    "    \"\"\"\n",
    "    From \n",
    "    Defines a local neighborhood and finds the local peaks\n",
    "    in the spectrogram, which must be larger than the specified `amp_min`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray, shape-(H, W)\n",
    "        The 2D array of data in which local peaks will be detected\n",
    "    \n",
    "    neighborhood : numpy.ndarray, shape-(h, w)\n",
    "        A boolean mask indicating the \"neighborhood\" in which each\n",
    "        datum will be assessed to determine whether or not it is\n",
    "        a local peak. h and w must be odd-valued numbers\n",
    "        \n",
    "    amp_min : float\n",
    "        All amplitudes at and below this value are excluded from being local \n",
    "        peaks.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Tuple[int, int]]\n",
    "        (row, col) index pair for each local peak location.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The local peaks are returned in column-major order.\n",
    "    \"\"\"\n",
    "    rows, cols = np.where(neighborhood)\n",
    "    assert neighborhood.shape[0] % 2 == 1\n",
    "    assert neighborhood.shape[1] % 2 == 1\n",
    "\n",
    "    rows -= neighborhood.shape[0] // 2\n",
    "    cols -= neighborhood.shape[1] // 2\n",
    "    \n",
    "    return _peaks(data_2d, rows, cols, amp_min=amp_min)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
